{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49ff437b-0a6c-4c3e-92fc-1ffd29ed54ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2100 validated image filenames belonging to 2 classes.\n",
      "Found 2100 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "66/66 [==============================] - 403s 6s/step - loss: 0.3689 - accuracy: 0.8505 - val_loss: 0.2317 - val_accuracy: 0.9033\n",
      "Epoch 2/2\n",
      "66/66 [==============================] - 377s 6s/step - loss: 0.1854 - accuracy: 0.9267 - val_loss: 0.1571 - val_accuracy: 0.9319\n",
      "66/66 [==============================] - 186s 3s/step - loss: 0.1571 - accuracy: 0.9319\n",
      "Test Accuracy: 0.9319047331809998\n",
      "Found 2100 validated image filenames belonging to 2 classes.\n",
      "Found 2100 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "66/66 [==============================] - 384s 6s/step - loss: 0.3251 - accuracy: 0.8710 - val_loss: 0.1794 - val_accuracy: 0.9267\n",
      "Epoch 2/2\n",
      "66/66 [==============================] - 370s 6s/step - loss: 0.1825 - accuracy: 0.9329 - val_loss: 0.1231 - val_accuracy: 0.9643\n",
      "66/66 [==============================] - 187s 3s/step - loss: 0.1231 - accuracy: 0.9643\n",
      "Test Accuracy: 0.9642857313156128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "NUM_FOLDS = 2\n",
    "DATA_DIR = \"D:/CAPSTONE 400A/final_dataset/Tuberculosis/TB_Chest_Radiography_Database/New_folder\"\n",
    "\n",
    "# Get the list of image filenames for each class\n",
    "normal_images = [os.path.join(DATA_DIR, \"Normal\", filename) for filename in os.listdir(os.path.join(DATA_DIR, \"Normal\"))]\n",
    "tb_images = [os.path.join(DATA_DIR, \"Tuberculosis\", filename) for filename in os.listdir(os.path.join(DATA_DIR, \"Tuberculosis\"))]\n",
    "\n",
    "# Create DataFrame to use with ImageDataGenerator\n",
    "df_normal = pd.DataFrame({'filename': normal_images, 'class': 'Normal'})\n",
    "df_tb = pd.DataFrame({'filename': tb_images, 'class': 'Tuberculosis'})\n",
    "df = pd.concat([df_normal, df_tb], ignore_index=True)\n",
    "\n",
    "# K-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True)\n",
    "\n",
    "# Initialize lists to store results\n",
    "all_true_labels = []\n",
    "all_predicted_labels = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X=df['filename'], y=df['class'])):\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    "\n",
    "    # Create data generators\n",
    "    train_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    test_generator = train_datagen.flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    # Define model\n",
    "    base_model = tf.keras.applications.EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.45),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Freeze pre-trained layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=len(test_generator)\n",
    "    )\n",
    "\n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ca5f84-b1db-4c74-888e-546e8d7c6aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 191s 3s/step\n",
      "66/66 [==============================] - 186s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "train_features = base_model.predict(train_generator)\n",
    "test_features = base_model.predict(test_generator)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3955d837-9b44-4674-9d73-4716e9145a93",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Reshape features\n",
    "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
    "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2d220a-ad86-49d9-b145-9295dfc565b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define subset size\n",
    "subset_size = 100  # Adjust this value as needed\n",
    "\n",
    "# Take a subset of the training features and classes\n",
    "train_features_subset = train_features_flat[:subset_size]\n",
    "train_classes_subset = train_generator.classes[:subset_size]\n",
    "\n",
    "try:\n",
    "    # Train XGBoost model\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_model.fit(train_features_subset, train_classes_subset)\n",
    "    \n",
    "    # If training completes successfully\n",
    "    print(\"XGBoost model trained successfully!\")\n",
    "\n",
    "except MemoryError:\n",
    "    print(\"MemoryError: Unable to allocate memory. Please reduce the dataset size or optimize data representation.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during training:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a9b9106-0602-4c2f-b86f-c5157171798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Evaluate XGBoost model\n",
    "xgb_predictions = xgb_model.predict(test_features_flat)\n",
    "xgb_accuracy = np.mean(xgb_predictions == test_generator.classes)\n",
    "print(\"XGBoost Accuracy:\", xgb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e11a37-5b00-4f3a-9d9e-7591171992a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
