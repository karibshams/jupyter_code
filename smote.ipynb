{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659da6b-c53b-49d1-938e-cbc4f703d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SentencePiece\n",
    "!pip install datasets\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f176e5b-aabf-4be1-adb5-21629f1d242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFXLMRobertaForSequenceClassification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "file_path = '/kaggle/input/xllm-data/dataset (2).csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e674e-b819-4876-902d-8febdf033092",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['encoded_emotion'] = label_encoder.fit_transform(data['Emotion'])\n",
    "data['Review'] = data['Review'].astype(str)\n",
    "train_data, test_data = train_test_split(\n",
    "    data, test_size=0.2, random_state=42, stratify=data['encoded_emotion']\n",
    ")\n",
    "#aritro ami train test e rakhsi only so eta change koris na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563aac0-dca6-4fda-b1ab-0a0f5894c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_labels = train_data['Review'].tolist(), train_data['encoded_emotion'].tolist()\n",
    "test_text, test_labels = test_data['Review'].tolist(), test_data['encoded_emotion'].tolist()\n",
    "\n",
    "# Tokenizer er moddhe ami smote use korsi\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "def tokenize_function(text_list):\n",
    "    return tokenizer(text_list, padding='max_length', truncation=True, max_length=128, return_tensors='tf')\n",
    "train_encodings = tokenize_function(train_text)\n",
    "test_encodings = tokenize_function(test_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d8770-ed33-4fc7-a9a4-b0ed066a41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    "))\n",
    "\n",
    "#  SMOTE apply korsi for  balancing the class\n",
    "X_train = np.array(train_encodings['input_ids'])  # token id nisi\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "#  SMOTE apply korsi to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "train_text_resampled = [tokenizer.decode(ids) for ids in X_res] \n",
    "train_labels_resampled = y_res\n",
    "train_encodings_resampled = tokenize_function(train_text_resampled)\n",
    "train_dataset_resampled = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings_resampled),\n",
    "    train_labels_resampled\n",
    "))\n",
    "model = TFXLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=len(label_encoder.classes_))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=4e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf8cc0-ee41-4f0a-853c-e6ac37fa7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset_resampled.shuffle(3000).batch(16), epochs=20, batch_size=16, validation_data=test_dataset.batch(16))\n",
    "\n",
    "eval_results = model.evaluate(test_dataset.batch(16))\n",
    "print(f\"Test Loss: {eval_results[0]}, Test Accuracy: {eval_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55296dc-6ef5-4aa6-a73d-e0a1af7d37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "y_pred = model.predict(test_dataset.batch(16)).logits\n",
    "y_pred = tf.argmax(y_pred, axis=1).numpy()\n",
    "\n",
    "unique_classes = np.unique(test_labels)\n",
    "\n",
    "#  unique classes\n",
    "target_names = [label_encoder.inverse_transform([cls])[0] for cls in unique_classes]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_labels, y_pred))\n",
    "precision = precision_score(test_labels, y_pred, average='macro')\n",
    "recall = recall_score(test_labels, y_pred, average='macro')\n",
    "f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64e168-3ff6-485c-99ce-02c97c9ca34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
